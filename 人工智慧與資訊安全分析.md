## 17	人工智慧與資訊安全分析:論文分析與實務測試
#### REVIEW導讀:
- [Privacy and Security Concerns in Generative AI: A Comprehensive Survey](https://www.ece.nus.edu.sg/stfpage/bsikdar/papers/access_genai_24.pdf)
- 2508 [Generative AI for Cybersecurity of Energy Management Systems: Methods, Challenges, and Future Directions](https://arxiv.org/abs/2508.10044)
- 2507 [Challenges in GenAI and Authentication: a scoping review](https://arxiv.org/abs/2507.11775)
- 2508 [Generative AI for Cybersecurity of Energy Management Systems: Methods, Challenges, and Future Directions](https://arxiv.org/abs/2508.10044)

#### PAPER 導讀:
- [Governing dual-use technologies: Case studies of international security agreements and lessons for AI governance](https://arxiv.org/abs/2409.02779)
- [Toward an African Agenda for AI Safety](https://arxiv.org/abs/2508.13179)

#### 自動化滲透測試
- 2507 [PenTest2.0: Towards Autonomous Privilege Escalation Using GenAI](https://arxiv.org/abs/2507.06742)
  - 由大型語言模型推理驅動的自動權限升級
  - PenTest++
  - PenTest Task Trees (PTTs) 
- 2023 PentestGPT: Evaluating and Harnessing Large Language Models for Automated Penetration Testing
  - https://pentestgpt.ai/
  - https://github.com/GreyDGL/PentestGPT
  - https://read01.com/y6DB0xO.html
  - https://arxiv.org/abs/2308.06782
  - Penetration Testing Benchmark 
- 2411 [AutoPT: How Far Are We from the End2End Automated Web Penetration Testing?](https://arxiv.org/abs/2411.01236)
- [2501.13411][ VulnBot: Autonomous Penetration Testing for A Multi-Agent Collaborative Framework ](https://arxiv.org/abs/2501.13411)
  - https://github.com/KHenryAegis/VulnBot 
- Autonomous penetration testing using reinforcement learning,” arXiv preprint arXiv:1905.05965, 2019
- [CAI: An Open, Bug Bounty-Ready Cybersecurity AI]()
- Excalibur: Automated penetration testing
#### 自動化滲透測試
- 靶機 https://www.vulnhub.com/entry/hackable-ii,711/
- 解答 
#### GenAI-powered Defense
- NAUTILUS: Automated RESTful API Vulnerability Detection
  - 韓國學生報告 https://mmlab.snu.ac.kr/community/seminar/2025-07-16-nautilus-automated-restful-api-vulnerability-detection/
  - https://sites.google.com/view/nautilus-testing
#### GenAI-powered Attack
- 2507 [Exploiting Jailbreaking Vulnerabilities in Generative AI to Bypass Ethical Safeguards for Facilitating Phishing Attacks](https://arxiv.org/abs/2507.12185)
  - 利用生成式人工智慧中的越獄漏洞繞過道德保障措施，從而促進網路釣魚攻擊
  - 如何透過越獄技術利用 GenAI 驅動的聊天機器人服務來繞過道德保障措施，從而產生網路釣魚內容、推薦駭客工具以及編排網路釣魚活動
  - GenAI 促進的網絡釣魚的新興趨勢
  - 模型可以成功指導新手用戶跨各種媒介執行網絡釣魚攻擊，包括網絡、電子郵件、短信（短信釣魚）和語音（網絡釣魚）
  - RQ1：是否有可能越獄 2025 年最大的兩個生成式 AI 聊天機器人服務，例如 DeepSeek 和 ChatGPT，以規避道德保障措施來生成網絡釣魚內容？
  - RQ2：生成式 AI 聊天機器人可以向天真的用戶推薦工具或建議平台來發動網路釣魚攻擊嗎？
  - RQ3：生成式 AI 聊天機器人能否為網路、電子郵件、簡訊、語音通話和其他可用於網路釣魚活動的攻擊媒介產生網路釣魚腳本？
  - RQ4：網路釣魚攻擊是否會因 GenAI 工具的可用性而激增？ 
- Jailbreaking Generative AI:Empowering Novices to Conduct PhishingAttacks. https://arxiv.org/abs/2503.01395. arXivpreprintarXiv:2503.01395.
- Jailbreaking chatgpt via prompt engineering: An empirical study,” arXiv preprint arXiv:2305.13860, 2023.
- Masterkey: Automated jailbreaking of large language model chatbots
- Prompt injection attack against llm-integrated applications
- Pandora: Jailbreak gpts by retrieval augmented generation poisoning
- 防禦
  - [SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks](https://arxiv.org/abs/2310.03684)
    - Jailbreaking Attacks ==> GCG, PAIR, RandomSearch, and AmpleGCG jailbreaks
    - https://github.com/arobey1/smooth-llm
#### 其他
  - [Microsoft Security Copilot: AI-Powered Security for All](https://www.youtube.com/watch?v=sNaxv2zflmc)
  - OWASP GenAI Security Project
  - [OWASP AI Security and Privacy Guide](https://owasp.org/www-project-ai-security-and-privacy-guide/)
