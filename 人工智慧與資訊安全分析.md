## 17	人工智慧與資訊安全分析:論文分析與實務測試
#### REVIEW導讀:
- [Privacy and Security Concerns in Generative AI: A Comprehensive Survey](https://www.ece.nus.edu.sg/stfpage/bsikdar/papers/access_genai_24.pdf)
- 2508 [Generative AI for Cybersecurity of Energy Management Systems: Methods, Challenges, and Future Directions](https://arxiv.org/abs/2508.10044)
- 2507 [Challenges in GenAI and Authentication: a scoping review](https://arxiv.org/abs/2507.11775)
- 2508 [Generative AI for Cybersecurity of Energy Management Systems: Methods, Challenges, and Future Directions](https://arxiv.org/abs/2508.10044)
- 2505 [Security Concerns for Large Language Models: A Survey](https://arxiv.org/abs/2505.18889)

#### PAPER 導讀:
- [Governing dual-use technologies: Case studies of international security agreements and lessons for AI governance](https://arxiv.org/abs/2409.02779)
- [Toward an African Agenda for AI Safety](https://arxiv.org/abs/2508.13179)

#### 主題 GenAI Digital Forensics and Incident Response (DFIR)
- 合成內容(DeepFake,....)的偵測
- 2502 REVIEW [Methods and Trends in Detecting Generated Images: A Comprehensive Review](https://arxiv.org/abs/2502.15176)
- 2505 [DFIR-Metric: A Benchmark Dataset for Evaluating Large Language Models in Digital Forensics and Incident Response](https://arxiv.org/abs/2505.19973)
  - https://github.com/DFIR-Metric
  - introduce a new metric, the Task Understanding Score (TUS), designed to more effectively evaluate models in scenarios where they achieve near-zero accuracy.
  - a benchmark with three components:
    - (1) Knowledge Assessment: a set of 700 expert-reviewed multiple-choice questions sourced from industry-standard certifications and official documentation;
    - (2) Realistic Forensic Challenges: 150 CTF-style tasks testing multi-step reasoning and evidence correlation;
    - (3) Practical Analysis: 500 disk and memory forensics cases from the NIST Computer Forensics Tool Testing Program (CFTT).
  - evaluated 14 LLMs using DFIR-Metric, analyzing both their accuracy and consistency across trials.
- 2502 [Comprehensive Digital Forensics and Risk Mitigation Strategy for Modern Enterprises](https://arxiv.org/abs/2502.19621)
#### 主題AI-based Attack and Defense: Malware Generation vs Malware Detection
- https://arxiv.org/search/?query=malware+&searchtype=all&source=header
- https://arxiv.org/search/?query=malware+generation&searchtype=all&source=header
- REVIEW [Large Language Model (LLM) for Software Security: Code Analysis, Malware Analysis, Reverse Engineering](https://arxiv.org/abs/2504.07137)
- [Detection of Malicious Codes Generated by Large Language Models: A Comparison of GPT-3.5, GPT-4o, Gemini, and Claude](https://dergipark.org.tr/en/pub/ijiss/issue/90977/1634763)
- Malware detection using transformers-based model gpt-2
- [Static Malware Detection Using Stacked BiLSTM and GPT-2]()
- 2405 [SoK: Leveraging Transformers for Malware Analysis](https://arxiv.org/pdf/2405.17190)
- 碩士論文[Snort Rule Generation for Malware Detection using the GPT2 Transformer](https://ruor.uottawa.ca/server/api/core/bitstreams/30564add-3aba-4545-a756-5a5da35feca7/content)
- [Explainable Malware Detection System Using Transformers-Based Transfer Learning and Multi-Model Visual Representation]()
- XLCNN: A TRANSFORMER MODEL FOR MALWARE DETECTION
- I-MAD: Interpretable malware detector using Galaxy Transformer
- ranDecepter: Real-time Identification and Deterrence of Ransomware Attacks
- Malware Analysis  Binary code analysis
  - 2505 [ReCopilot: Reverse Engineering Copilot in Binary Analysis](https://arxiv.org/abs/2505.16366)
  - 2504 [An Empirical Study on the Effectiveness of Large Language Models for Binary Code Understanding](https://arxiv.org/abs/2504.21803)
- Malware Generation
  - MGC: A Compiler Framework Exploiting Compositional Blindness in Aligned LLMs for Malware Generation
  - [LLM Agents can Autonomously Exploit One-day Vulnerabilities](https://arxiv.org/abs/2404.08144)
  - 2506 [MalGEN: A Generative Agent Framework for Modeling Malicious Software in Cybersecurity](https://arxiv.org/abs/2506.07586)
  - [Mal-D2GAN: Double-Detector based GAN for Malware Generation](https://arxiv.org/abs/2505.18806)
  - Deep exploit
    - https://github.com/TheDreamPort/deep_exploit
    - https://github.com/13o-bbr-bbq/machine_learning_security 
#### LLM-powered secure code review
- 資料集 2304 [DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection](https://arxiv.org/abs/2304.00409)
  - https://github.com/wagner-group/diversevul
- 資料集LLMSecEval[2303.09384] [ LLMSecEval: A Dataset of Natural Language ](https://arxiv.org/abs/2303.09384)
- 資料集SecurityEval
  - https://s2e-lab.github.io/preprints/msr4ps22-preprint.pdf
  - https://github.com/s2e-lab/SecurityEval
  - https://huggingface.co/datasets/s2e-lab/SecurityEval
  - SecurityEval Dataset: Mining Vulnerability Examples to Evaluate Machine Learning-Based Code Generation Techniques
- 2502 [Benchmarking Prompt Engineering Techniques for Secure Code Generation with GPT Models](https://arxiv.org/abs/2502.06039)
  - Can we enhance GPT’s secure code generation via prompt engineering?
- [Detecting Code Vulnerabilities using LLMs](https://seclab.skku.edu/wp-content/uploads/2025/07/DSN2025__LLM_Vulnerability_Detection_CR.pdf) 

#### 專題:自動化滲透測試
- 2507 [PenTest2.0: Towards Autonomous Privilege Escalation Using GenAI](https://arxiv.org/abs/2507.06742)
  - 由大型語言模型推理驅動的自動權限升級
  - PenTest++
  - PenTest Task Trees (PTTs) 
- 2023 PentestGPT: Evaluating and Harnessing Large Language Models for Automated Penetration Testing
  - https://pentestgpt.ai/
  - https://github.com/GreyDGL/PentestGPT
  - https://read01.com/y6DB0xO.html
  - https://arxiv.org/abs/2308.06782
  - Penetration Testing Benchmark 
- 2411 [AutoPT: How Far Are We from the End2End Automated Web Penetration Testing?](https://arxiv.org/abs/2411.01236)
- [2501.13411][ VulnBot: Autonomous Penetration Testing for A Multi-Agent Collaborative Framework ](https://arxiv.org/abs/2501.13411)
  - https://github.com/KHenryAegis/VulnBot 
- Autonomous penetration testing using reinforcement learning,” arXiv preprint arXiv:1905.05965, 2019
- 2504 [CAI: An Open, Bug Bounty-Ready Cybersecurity AI](https://arxiv.org/abs/2504.06017)
  - Cybersecurity AI (CAI)
  - CAI框架是一個輕量級的開源框架，可免費用於研究目的，旨在建立在人類競爭水平上運行的專門安全測試代理。
  - CAI 為創建「漏洞賞金就緒」的人工智慧系統提供了構建塊，這些系統可以自我評估不同技術和環境中的安全態勢。
  - 透過結合模組化代理設計、無縫工具整合和人工監督功能，CAI 使各種規模的組織能夠利用 AI 進行安全運營，而這些操作以前只有擁有大量安全預算的大型企業才能使用。
  - 該框架的方法透過其開放式架構、靈活性以及專注於與現實世界測試方法一致的實際安全結果來解決現有解決方案中的關鍵差距。
  - 透過這樣做，CAI 旨在消除目前主導平台強加的鎖定，提供一種民主化的替代方案，使較小的實體能夠參與漏洞發現，而不受專有系統和獨家合約的限制。 
- Excalibur: Automated penetration testing
- 2404 [LLM Agents can Autonomously Exploit One-day Vulnerabilities](https://arxiv.org/abs/2404.08144)
- Autoattacker: A large language model guided system to implement automatic cyber-attacks
- Pentestagent: Incorporating llm agents to automated penetration testing
- Penheal: A two-stage llm framework for automated pentesting and optimal remediation
- An empirical evaluation of llms for solving offensive security challenges
- [2025 AI vs Human CTF Challenge](https://ctf.hackthebox.com/event/details/ai-vs-human-ctf-challenge-2000)
- Google announces Sec-Gemini v1, a new experimental cybersecurity model
  - https://secgemini.google/ 
- Aptori:AI 驅動的自動化平台，提供全方位 API 安全測試與弱點修補
  - https://www.aptori.com/ 

#### 自動化滲透測試實測
- 靶機 https://www.vulnhub.com/entry/hackable-ii,711/
- 解答
  - https://www.cnblogs.com/sainet/p/15752013.html
  - https://blog.csdn.net/qq_43017750/article/details/118330748
  - https://www.sxrhhh.top/writeups/2024/12/19/vulnhubhackable-ii/
  - [Hackable: II Vulnhub Walkthrough](https://www.youtube.com/watch?v=4LnDkdlnt8Y)
- PentestGPT 自動化滲透測試實測

#### GenAI-powered Defense
- NAUTILUS: Automated RESTful API Vulnerability Detection
  - 韓國學生報告 https://mmlab.snu.ac.kr/community/seminar/2025-07-16-nautilus-automated-restful-api-vulnerability-detection/
  - https://sites.google.com/view/nautilus-testing

#### GenAI-powered Attack
- 2507 [Exploiting Jailbreaking Vulnerabilities in Generative AI to Bypass Ethical Safeguards for Facilitating Phishing Attacks](https://arxiv.org/abs/2507.12185)
  - 利用生成式人工智慧中的越獄漏洞繞過道德保障措施，從而促進網路釣魚攻擊
  - 如何透過越獄技術利用 GenAI 驅動的聊天機器人服務來繞過道德保障措施，從而產生網路釣魚內容、推薦駭客工具以及編排網路釣魚活動
  - GenAI 促進的網絡釣魚的新興趨勢
  - 模型可以成功指導新手用戶跨各種媒介執行網絡釣魚攻擊，包括網絡、電子郵件、短信（短信釣魚）和語音（網絡釣魚）
  - RQ1：是否有可能越獄 2025 年最大的兩個生成式 AI 聊天機器人服務，例如 DeepSeek 和 ChatGPT，以規避道德保障措施來生成網絡釣魚內容？
  - RQ2：生成式 AI 聊天機器人可以向天真的用戶推薦工具或建議平台來發動網路釣魚攻擊嗎？
  - RQ3：生成式 AI 聊天機器人能否為網路、電子郵件、簡訊、語音通話和其他可用於網路釣魚活動的攻擊媒介產生網路釣魚腳本？
  - RQ4：網路釣魚攻擊是否會因 GenAI 工具的可用性而激增？ 
- Jailbreaking Generative AI:Empowering Novices to Conduct PhishingAttacks. https://arxiv.org/abs/2503.01395. arXivpreprintarXiv:2503.01395.
- Jailbreaking chatgpt via prompt engineering: An empirical study,” arXiv preprint arXiv:2305.13860, 2023.
- Masterkey: Automated jailbreaking of large language model chatbots
- Prompt injection attack against llm-integrated applications
- Pandora: Jailbreak gpts by retrieval augmented generation poisoning
- 防禦
  - [SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks](https://arxiv.org/abs/2310.03684)
    - Jailbreaking Attacks ==> GCG, PAIR, RandomSearch, and AmpleGCG jailbreaks
    - https://github.com/arobey1/smooth-llm
#### 其他
  - [Microsoft Security Copilot: AI-Powered Security for All](https://www.youtube.com/watch?v=sNaxv2zflmc)
  - OWASP GenAI Security Project
  - [OWASP AI Security and Privacy Guide](https://owasp.org/www-project-ai-security-and-privacy-guide/)
