# ğŸ“˜ TensorFlow Model Optimization æ¨¡çµ„æ•™å­¸æ–‡ä»¶
**Author**ï¼šChatGPT GPT-5  
**Language**ï¼šç¹é«”ä¸­æ–‡ / English  
**Purpose**ï¼šèªªæ˜å¦‚ä½•ä½¿ç”¨ `tensorflow-model-optimization` é€²è¡Œæ¨¡å‹å£“ç¸®ï¼ˆcompressionï¼‰ã€å‰ªæï¼ˆpruningï¼‰ã€é‡åŒ–ï¼ˆquantizationï¼‰èˆ‡æ•ˆèƒ½æœ€ä½³åŒ–ï¼ˆoptimizationï¼‰  

---

## ğŸ§© ä¸€ã€æ¨¡çµ„ç°¡ä»‹ (Overview)

`tensorflow-model-optimization`ï¼ˆç°¡ç¨± **TFMO**ï¼‰æ˜¯ TensorFlow å®˜æ–¹æ¨å‡ºçš„æ¨¡å‹æœ€ä½³åŒ–å¥—ä»¶ï¼Œ
æä¾›å¤šç¨®æ–¹æ³•è®“é–‹ç™¼è€…åœ¨ **ä¸å¤§å¹…é™ä½æº–ç¢ºç‡** çš„æƒ…æ³ä¸‹ï¼Œé¡¯è‘—æ¸›å°‘æ¨¡å‹å¤§å°ä¸¦æå‡æ¨è«–é€Ÿåº¦ã€‚

æ ¸å¿ƒåŠŸèƒ½åŒ…æ‹¬ï¼š
- âœ‚ï¸ **å‰ªæ (Pruning)**ï¼šç§»é™¤å°çµæœå½±éŸ¿è¼ƒå°çš„æ¬Šé‡  
- âš–ï¸ **é‡åŒ– (Quantization)**ï¼šå°‡æµ®é»æ¨¡å‹è½‰ç‚ºä½ä½å…ƒæ•´æ•¸è¡¨ç¤ºï¼ˆå¦‚ int8ï¼‰  
- ğŸ§± **èšé¡ (Clustering)**ï¼šå°‡æ¬Šé‡åˆ†çµ„ä»¥æ¸›å°‘åƒæ•¸å¤šæ¨£æ€§  
- ğŸš€ **æ•´åˆéƒ¨ç½² (Deployment-ready)**ï¼šå¯ç›´æ¥å°å‡ºè‡³ TensorFlow Liteã€Edge TPUã€æˆ– ONNX  

---

## âš™ï¸ äºŒã€å®‰è£æ¨¡çµ„ (Installation)

```bash
pip install -q tensorflow-model-optimization matplotlib
```

ç¢ºèªå®‰è£ç‰ˆæœ¬ï¼š
```python
import tensorflow_model_optimization as tfmot
print(tfmot.__version__)
```

---

## ğŸ§  ä¸‰ã€æ‡‰ç”¨å ´æ™¯ (Use Cases)

| æŠ€è¡“ | èªªæ˜ | ä¸»è¦ç”¨é€” |
|------|------|-----------|
| å‰ªæ Pruning | ç§»é™¤æ¬Šé‡ä¸­å†—é¤˜é€£æ¥ | æ¸›å°‘æ¨¡å‹å¤§å° |
| é‡åŒ– Quantization | å°‡ float32 â†’ int8 | åŠ é€Ÿæ¨è«–ã€é™ä½è¨˜æ†¶é«”ä½¿ç”¨ |
| èšé¡ Clustering | å°‡ç›¸ä¼¼æ¬Šé‡èšåˆæˆå°‘é‡ä»£è¡¨å€¼ | é€²ä¸€æ­¥å£“ç¸®æ¨¡å‹ |
| æ··åˆæœ€ä½³åŒ– Mixed Optimization | çµåˆå‰ªæèˆ‡é‡åŒ– | æ¥µè‡´å£“ç¸®èˆ‡æ•ˆèƒ½æå‡ |

---

## âœ‚ï¸ å››ã€æ¨¡å‹å‰ªæ (Model Pruning)

```python
import tensorflow as tf
import tensorflow_model_optimization as tfmot

# å®šç¾©å‰ªæåƒæ•¸
prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude
pruning_params = {
    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(
        initial_sparsity=0.0,
        final_sparsity=0.5,
        begin_step=0,
        end_step=1000
    )
}

# åŸå§‹æ¨¡å‹
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    tf.keras.layers.Dense(10, activation='softmax')
])

# å¥—ç”¨å‰ªæ
model_for_pruning = prune_low_magnitude(model, **pruning_params)
model_for_pruning.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
```

âœ… è¨“ç·´å¾Œä½¿ç”¨ï¼š
```python
model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)
model_for_export.save('pruned_model.h5')
```

---

## âš–ï¸ äº”ã€æ¨¡å‹é‡åŒ– (Model Quantization)

### ğŸ”¹ 1ï¸âƒ£ å¾Œè¨“ç·´é‡åŒ– (Post-training Quantization)

```python
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_quant_model = converter.convert()

with open("quant_model.tflite", "wb") as f:
    f.write(tflite_quant_model)
```

### ğŸ”¹ 2ï¸âƒ£ è¨“ç·´æ™‚é‡åŒ– (Quantization Aware Training, QAT)

```python
quantize_model = tfmot.quantization.keras.quantize_model
q_aware_model = quantize_model(model)
q_aware_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
```

---

## ğŸ§± å…­ã€æ¨¡å‹èšé¡ (Weight Clustering)

```python
clustering_params = {
    'number_of_clusters': 16,
    'cluster_centroids_init': tfmot.clustering.keras.CentroidInitialization.LINEAR
}

cluster_model = tfmot.clustering.keras.cluster_weights(model, **clustering_params)
cluster_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
```

åŒ¯å‡ºæ¨¡å‹ï¼š
```python
final_model = tfmot.clustering.keras.strip_clustering(cluster_model)
final_model.save('clustered_model.h5')
```

---

## ğŸ“Š ä¸ƒã€æ¨¡å‹å£“ç¸®å‰å¾Œå°ç…§åœ– (Visualization of Model Compression)

æ­¤æ®µç¤ºç¯„å¦‚ä½•ä½¿ç”¨ `matplotlib` æ¯”è¼ƒæ¨¡å‹å£“ç¸®å‰å¾Œçš„å¤§å°èˆ‡æ¨è«–é€Ÿåº¦ã€‚

```python
import matplotlib.pyplot as plt

labels = ['Original', 'Pruned', 'Quantized', 'Hybrid']
size_mb = [20, 12, 5, 4]  # æ¨¡å‹å¤§å°ï¼ˆMBï¼‰
speed = [1.0, 1.2, 2.0, 2.5]  # ç›¸å°æ¨è«–é€Ÿåº¦

fig, ax1 = plt.subplots()
ax2 = ax1.twinx()
ax1.bar(labels, size_mb, color='skyblue', label='Model Size (MB)')
ax2.plot(labels, speed, color='orange', marker='o', label='Speed (x)')

ax1.set_xlabel('Model Type')
ax1.set_ylabel('Size (MB)', color='blue')
ax2.set_ylabel('Speed (x)', color='orange')
ax1.set_title('ğŸ“Š æ¨¡å‹å£“ç¸®å‰å¾Œæ•ˆèƒ½å°ç…§åœ–')

fig.legend(loc='upper right')
plt.show()
```

ğŸ“ˆ **çµæœèªªæ˜**ï¼š
- æ¨¡å‹å¤§å°ç¸®å°ç´„ 80%ï¼Œæ¨è«–é€Ÿåº¦æœ€é«˜å¯é” 2.5 å€ã€‚
- è‹¥çµåˆé‡åŒ–èˆ‡å‰ªæï¼Œé©åˆé‚Šç·£è£ç½®éƒ¨ç½²ã€‚

---

## âš™ï¸ å…«ã€TensorFlow Lite Ã— Edge TPU å¯¦éš›éƒ¨ç½²æµç¨‹

### âœ… éƒ¨ç½²æ­¥é©Ÿï¼š

1ï¸âƒ£ **åŒ¯å‡ºé‡åŒ–æ¨¡å‹ï¼š**
```python
converter = tf.lite.TFLiteConverter.from_keras_model(final_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()
open('optimized_model.tflite', 'wb').write(tflite_model)
```

2ï¸âƒ£ **Edge TPU ç·¨è­¯ï¼š**
```bash
edgetpu_compiler optimized_model.tflite
```

3ï¸âƒ£ **åœ¨æ¨¹è“æ´¾æˆ– Coral Dev Board ä¸ŠåŸ·è¡Œï¼š**
```bash
python3 infer_tflite.py --model optimized_model_edgetpu.tflite --image test.jpg
```

4ï¸âƒ£ **é©—è­‰æ•ˆèƒ½ï¼š**
- æª¢æŸ¥ FPS èˆ‡å»¶é²æ™‚é–“ï¼ˆLatencyï¼‰
- èˆ‡åŸå§‹æ¨¡å‹é€²è¡Œæ¯”è¼ƒ

---

## ğŸ§  ä¹ã€æ¨¡å‹å£“ç¸® Ã— AI é¢¨éšªç®¡ç† (NIST AI RMF æ‡‰ç”¨)

æ¨¡å‹å£“ç¸®æŠ€è¡“åœ¨ NIST AI RMFï¼ˆArtificial Intelligence Risk Management Frameworkï¼‰ä¸­å±¬æ–¼ **â€œç³»çµ±é¢¨éšª (Systemic Risk)â€** èˆ‡ **â€œæŠ€è¡“é¢¨éšª (Technical Risk)â€** æ§åˆ¶å±¤é¢ï¼Œä¸»è¦å½±éŸ¿ï¼š

| é¢¨éšªé¡åˆ¥ | èªªæ˜ | å°æ‡‰æ§åˆ¶æªæ–½ |
|-----------|-----------|----------------|
| **Accuracy Risk** | å‰ªæèˆ‡é‡åŒ–å¯èƒ½é™ä½æ¨¡å‹æº–ç¢ºç‡ | ä½¿ç”¨é©—è­‰é›†é‡æ–°æ ¡æº–æ¨¡å‹ç²¾åº¦ |
| **Robustness Risk** | å£“ç¸®å¾Œæ¨¡å‹å°å°æŠ—æ¨£æœ¬æ•æ„Ÿåº¦æé«˜ | çµåˆ adversarial training æ¸›è¼•å½±éŸ¿ |
| **Explainability Risk** | æ¬Šé‡å£“ç¸®å¾Œæ¨¡å‹å¯è§£é‡‹æ€§ä¸‹é™ | ç´€éŒ„å£“ç¸®åƒæ•¸èˆ‡å¯è¿½æº¯æ€§å ±å‘Š |
| **Bias Propagation Risk** | æ¨¡å‹å£“ç¸®å¯èƒ½æ”¾å¤§è³‡æ–™åå·® | æ–¼å£“ç¸®å‰å¾Œé€²è¡Œå…¬å¹³æ€§æ¸¬è©¦ |

### ğŸ” å»ºè­°å°ç­–ï¼š
- å»ºç«‹ **æ¨¡å‹å£“ç¸®å¯©æŸ¥ç¨‹åº (Compression Review Process)**ã€‚
- ç´€éŒ„æ¯æ¬¡å£“ç¸®æ­¥é©Ÿèˆ‡å°æ‡‰ç²¾åº¦è®ŠåŒ–ã€‚
- ç´å…¥ AI RMF â€œMAPâ€ éšæ®µï¼ˆMeasure, Analyze, Prepareï¼‰æ–‡ä»¶ã€‚  

ğŸ“š **å»¶ä¼¸åƒè€ƒï¼š**
- NIST AI RMF 1.0 Section 3.2 â€œSystemic Riskâ€  
- AI RMF: Generative AI Profile (2024 Draft) â€” æŠ€è¡“é¢¨éšªèˆ‡æ•ˆèƒ½å¹³è¡¡  

---

## ğŸ“ˆ åã€æ•ˆèƒ½æ¯”è¼ƒ (Performance Comparison)

| æ¨¡å‹é¡å‹ | æ¨¡å‹å¤§å° | æ¨è«–é€Ÿåº¦ | æº–ç¢ºç‡è®ŠåŒ– |
|-----------|-----------|-----------|-------------|
| åŸå§‹æ¨¡å‹ | 100% | 1x | baseline |
| å‰ªæå¾Œ | ç´„ 60% | ç´„ 1.2x | Â±1% |
| é‡åŒ–å¾Œ | ç´„ 25% | ç´„ 2x | Â±2% |
| å‰ªæ + é‡åŒ– | ç´„ 20% | ç´„ 2.5x | Â±3% |

---

## ğŸ“š åä¸€ã€å»¶ä¼¸é–±è®€ (Further Reading)

- ğŸ”— [TensorFlow Model Optimization å®˜æ–¹ç¶²ç«™](https://www.tensorflow.org/model_optimization)  
- ğŸ“˜ [Pruning API Docs](https://www.tensorflow.org/model_optimization/guide/pruning)  
- âš–ï¸ [Quantization API Docs](https://www.tensorflow.org/model_optimization/guide/quantization)  
- ğŸ§± [Clustering API Docs](https://www.tensorflow.org/model_optimization/guide/clustering)  
- ğŸ§  [NIST AI RMF å®˜æ–¹æ–‡ä»¶](https://www.nist.gov/itl/ai-risk-management-framework)  

---

## âœ… æ•™å­¸é‡é»å›é¡§ (Summary)

| ä¸»é¡Œ | é‡é» |
|------|------|
| å‰ªæ | ç§»é™¤æ¬Šé‡ç¨€ç–é€£æ¥ä»¥æ¸›å°‘æ¨¡å‹å¤§å° |
| é‡åŒ– | å°‡æµ®é»æ•¸è½‰ç‚ºæ•´æ•¸ä»¥åŠ é€Ÿæ¨è«– |
| èšé¡ | å£“ç¸®æ¬Šé‡åƒæ•¸ç©ºé–“ |
| æ¨¡å‹å£“ç¸®è¦–è¦ºåŒ– | Matplotlib ç¹ªè£½æ¨¡å‹å¤§å°èˆ‡é€Ÿåº¦è®ŠåŒ– |
| Edge TPU éƒ¨ç½² | å¯¦éš›ç·¨è­¯èˆ‡æ¸¬è©¦éƒ¨ç½²æµç¨‹ |
| AI é¢¨éšªç®¡ç† | å°æ‡‰ NIST AI RMF æŠ€è¡“é¢¨éšªæ§åˆ¶ |

---

Â© 2025 ChatGPT GPT-5

