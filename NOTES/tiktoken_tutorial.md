# ğŸ“˜ Tiktoken æ¨¡çµ„æ•™å­¸æ–‡ä»¶  
**Author**ï¼šChatGPT GPT-5  
**Language**ï¼šç¹é«”ä¸­æ–‡ / English  
**Purpose**ï¼šç†è§£ OpenAI Token æ¦‚å¿µèˆ‡ä½¿ç”¨ Python `tiktoken` æ¨¡çµ„é€²è¡Œåˆ†è©èˆ‡æˆæœ¬è¨ˆç®—  

---

## ğŸ§© ä¸€ã€ä»€éº¼æ˜¯ Tiktokenï¼Ÿ (What is Tiktoken?)

`tiktoken` æ˜¯ OpenAI å®˜æ–¹é–‹æºçš„ **é«˜æ•ˆæ–‡å­—åˆ†è©ï¼ˆtokenizationï¼‰åº«**ï¼Œ  
å¯å°‡æ–‡å­—è½‰ç‚º LLM æ¨¡å‹èƒ½ç†è§£çš„æœ€å°å–®ä½ï¼ˆtokenï¼‰ï¼Œå¸¸ç”¨æ–¼ï¼š

- ğŸ”¢ é ä¼°æ¨¡å‹ Token æˆæœ¬ï¼ˆtoken cost estimationï¼‰  
- ğŸ“ æ§åˆ¶ Prompt é•·åº¦ï¼ˆprompt length controlï¼‰  
- âš™ï¸ å»ºç«‹æ–‡æœ¬åˆ†å¡Šï¼ˆtext chunkingï¼‰  
- ğŸ“Š åˆ†æèªæ–™é•·åº¦èˆ‡çµæ§‹  

---

## ğŸ§  äºŒã€Token æ¦‚å¿µ (Understanding Tokens)

| åç¨± | èªªæ˜ | ç¯„ä¾‹ |
|------|------|------|
| **æ–‡å­— (Text)** | äººé¡å¯è®€èªè¨€ | â€œChatGPT çœŸå²å®³ï¼â€ |
| **Token** | æ¨¡å‹ç†è§£å–®ä½ | [â€œChatâ€, â€œGâ€, â€œPTâ€, â€œ çœŸâ€, â€œå²â€, â€œå®³â€, â€œï¼â€] |
| **Encoding** | æ–‡å­—è½‰æ•¸å­— ID | [1234, 567, 890, â€¦] |

> ğŸ’¡ GPT-4 æ¨¡å‹æœ€å¤§ä¸Šä¸‹æ–‡é•·åº¦ï¼ˆcontext lengthï¼‰ç´„ **128K tokens**ï¼Œ  
> ç´„ç­‰æ–¼ 100K ä¸­æ–‡å­— æˆ– 80K è‹±æ–‡å–®å­—ã€‚

---

## âš™ï¸ ä¸‰ã€å®‰è£æ¨¡çµ„ (Installation)

```bash
pip install tiktoken matplotlib streamlit
```

---

## ğŸ§‘â€ğŸ’» å››ã€åŸºæœ¬ä½¿ç”¨æ•™å­¸ (Basic Usage)

```python
import tiktoken

# é¸æ“‡æ¨¡å‹ç·¨ç¢¼å™¨ (e.g. GPT-4)
encoding = tiktoken.encoding_for_model("gpt-4")

# ç·¨ç¢¼ (Encode text â†’ token IDs)
tokens = encoding.encode("Hello! é€™æ˜¯ä¸€æ®µæ¸¬è©¦æ–‡å­—ã€‚")
print(tokens)

# è§£ç¢¼ (Decode token IDs â†’ text)
print(encoding.decode(tokens))

# è¨ˆç®— token æ•¸é‡
print(f"Token æ•¸é‡ï¼š{len(tokens)}")
```

ğŸ“Š **è¼¸å‡ºç¯„ä¾‹ (Example Output)**  
```
[9906, 0, 3450, 152, ...]
Hello! é€™æ˜¯ä¸€æ®µæ¸¬è©¦æ–‡å­—ã€‚
Token æ•¸é‡ï¼š12
```

---

## ğŸ§® äº”ã€ä¸åŒæ¨¡å‹çš„ Token å·®ç•° (Token Count Comparison)

```python
text = "OpenAI çš„ GPT æ¨¡å‹éå¸¸å¼·å¤§ï¼"

for model in ["gpt-3.5-turbo", "gpt-4", "text-davinci-003"]:
    enc = tiktoken.encoding_for_model(model)
    print(f"{model} -> {len(enc.encode(text))} tokens")
```

| æ¨¡å‹ (Model) | Token æ•¸é‡ |
|---------------|-------------|
| gpt-3.5-turbo | 11 |
| gpt-4 | 12 |
| text-davinci-003 | 14 |

---

## ğŸ§° å…­ã€è‡ªè¨‚ç·¨ç¢¼å™¨ (Custom Encoder)

```python
enc = tiktoken.get_encoding("cl100k_base")

text = "äººå·¥æ™ºæ…§æ”¹è®Šä¸–ç•Œã€‚"
tokens = enc.encode(text, allowed_special={"<|endoftext|>"})
print(tokens)
```

---

## ğŸ§¾ ä¸ƒã€è¨ˆç®— Token æˆæœ¬ (Token Cost Estimation)

```python
def calc_token_cost(text: str, model: str = "gpt-4", rate_per_1k: float = 0.01):
    enc = tiktoken.encoding_for_model(model)
    tokens = len(enc.encode(text))
    cost = (tokens / 1000) * rate_per_1k
    return tokens, cost

sample = "é€™æ˜¯ä¸€å€‹ç”¨æ–¼ä¼°ç®—æˆæœ¬çš„ç¯„ä¾‹æ–‡å­—ã€‚"
t, c = calc_token_cost(sample, "gpt-4-turbo", 0.01)
print(f"å…± {t} tokensï¼Œç´„ ${c:.4f} ç¾å…ƒ")
```

---

## ğŸ§© å…«ã€åœ¨ LLM æ‡‰ç”¨ä¸­æ•´åˆ (Integration in LLM Apps)

```python
def chunk_text(text, model="gpt-4", max_tokens=200):
    enc = tiktoken.encoding_for_model(model)
    tokens = enc.encode(text)
    chunks = [tokens[i:i + max_tokens] for i in range(0, len(tokens), max_tokens)]
    return [enc.decode(chunk) for chunk in chunks]
```

> ğŸ“˜ æ‡‰ç”¨ï¼šRAG (Retrieval-Augmented Generation) æ–‡ä»¶åˆ‡ç‰‡ã€‚

---

## ğŸ§  ä¹ã€å¸¸è¦‹ç·¨ç¢¼å™¨å°ç…§è¡¨ (Encoding Reference Table)

| ç·¨ç¢¼åç¨± | å°æ‡‰æ¨¡å‹ | æœ€å¤§é•·åº¦ (Max Tokens) |
|-----------|-----------|----------------|
| `p50k_base` | GPT-3 ç³»åˆ— | 4K â€“ 16K |
| `r50k_base` | Codex ç³»åˆ— | 8K |
| `cl100k_base` | GPT-3.5 / GPT-4 ç³»åˆ— | 100K â€“ 128K |

---

## ğŸ§® ğŸ”¢ åã€Token å¯è¦–åŒ–èˆ‡æˆæœ¬è©¦ç®—ç¯„ä¾‹ (Visualization & Cost Dashboard)

æ­¤ç« ç¯€å±•ç¤ºå¦‚ä½•ä½¿ç”¨ `matplotlib` èˆ‡ `streamlit` äº’å‹•å¼å‘ˆç¾ Token åˆ†å¸ƒèˆ‡è²»ç”¨ä¼°ç®—ã€‚

### ğŸ“Š ç¯„ä¾‹ä¸€ï¼šMatplotlib Token é•·åº¦åˆ†å¸ƒ

```python
import matplotlib.pyplot as plt
import tiktoken

texts = [
    "Hello world!",
    "é€™æ˜¯ä¸€æ®µä¸­æ–‡æ¸¬è©¦æ–‡å­—ã€‚",
    "OpenAI GPT æ¨¡å‹èƒ½ç†è§£å¤šèªè¨€è¼¸å…¥ã€‚"
]

encoding = tiktoken.encoding_for_model("gpt-4")
lengths = [len(encoding.encode(t)) for t in texts]

plt.bar(range(len(texts)), lengths, color='skyblue')
plt.xticks(range(len(texts)), [f"Text {i+1}" for i in range(len(texts))])
plt.ylabel("Token æ•¸é‡")
plt.title("ä¸åŒæ–‡å­—çš„ Token é•·åº¦åˆ†å¸ƒåœ–")
plt.show()
```

### ğŸ’° ç¯„ä¾‹äºŒï¼šStreamlit æˆæœ¬è©¦ç®—å„€è¡¨æ¿

```python
import streamlit as st
import tiktoken

def calc_tokens(text, model="gpt-4-turbo"):
    enc = tiktoken.encoding_for_model(model)
    return len(enc.encode(text))

st.title("ğŸ”¢ Token æˆæœ¬è©¦ç®— Dashboard")
text = st.text_area("è¼¸å…¥è¦åˆ†æçš„æ–‡å­—ï¼š", "ChatGPT æ˜¯éå¸¸å¼·å¤§çš„ AI æ¨¡å‹ã€‚")
model = st.selectbox("é¸æ“‡æ¨¡å‹ï¼š", ["gpt-4-turbo", "gpt-3.5-turbo", "text-davinci-003"])
rate = st.number_input("æ¯ 1000 Tokens æˆæœ¬ (USD)ï¼š", 0.001, 0.05, 0.01, 0.001)

tokens = calc_tokens(text, model)
cost = tokens / 1000 * rate

st.metric(label="Token æ•¸é‡", value=tokens)
st.metric(label="é ä¼°æˆæœ¬ (USD)", value=f"${cost:.4f}")
```

âœ… é‹è¡ŒæŒ‡ä»¤ï¼š
```bash
streamlit run token_dashboard.py
```

ğŸ“ˆ **çµæœå±•ç¤º**ï¼š
- è¼¸å…¥ä»»æ„æ–‡å­—ï¼Œå¯¦æ™‚é¡¯ç¤º Token æ•¸é‡èˆ‡è²»ç”¨ã€‚  
- é©åˆ LLM å°å…¥å‰çš„é ç®—åˆ†æèˆ‡ prompt æœ€ä½³åŒ–ã€‚

---

## ğŸ§© åä¸€ã€æ‡‰ç”¨å ´æ™¯ (Use Cases)

- ğŸ“ **æ§åˆ¶ Prompt é•·åº¦**ï¼šé˜²æ­¢è¶…éæ¨¡å‹é™åˆ¶  
- ğŸ’° **è²»ç”¨é ä¼° (Cost Estimation)**ï¼šAPI è¨ˆè²»æ§ç®¡  
- ğŸ§© **RAG æ–‡æœ¬åˆ†å¡Š (Chunking)**  
- ğŸ” **èªæ–™çµ±è¨ˆåˆ†æ (Corpus Analysis)**  

---

## ğŸ§¾ åäºŒã€å®Œæ•´ç¯„ä¾‹ (Complete Example)

```python
"""
tiktoken_demo.py
èªªæ˜ï¼šç¤ºç¯„å¦‚ä½•ç”¨ tiktoken è¨ˆç®— token æ•¸èˆ‡æˆæœ¬
"""
import tiktoken

def token_info(text: str, model: str = "gpt-4-turbo"):
    enc = tiktoken.encoding_for_model(model)
    tokens = enc.encode(text)
    print(f"æ¨¡å‹ï¼š{model}")
    print(f"æ–‡å­—ï¼š{text}")
    print(f"Token æ•¸é‡ï¼š{len(tokens)}")
    print(f"Tokensï¼š{tokens}")
    print(f"é‚„åŸæ–‡å­—ï¼š{enc.decode(tokens)}")

if __name__ == "__main__":
    token_info("Tiktoken æ˜¯ä¸€å€‹é«˜æ•ˆèƒ½çš„åˆ†è©æ¨¡çµ„ã€‚")
```

---

## ğŸ“š åä¸‰ã€å»¶ä¼¸é–±è®€ (Further Reading)

- ğŸ”— [Tiktoken å®˜æ–¹ GitHub](https://github.com/openai/tiktoken)  
- ğŸ’° [OpenAI API å®šåƒ¹è¡¨](https://openai.com/pricing)  
- ğŸ” [ç·šä¸Šåˆ†è©å¯è¦–åŒ–å·¥å…·](https://tiktokenizer.vercel.app)

---

## âœ… æ•™å­¸é‡é»å›é¡§ (Summary)

| ä¸»é¡Œ | é‡é» |
|------|------|
| Token æ˜¯ LLM çš„åŸºæœ¬å–®ä½ | ä¸€å€‹å­—æˆ–è©ç‰‡æ®µ |
| Tiktoken åŠŸèƒ½ | åˆ†è©ã€åˆä½µã€è¨ˆè²»ã€æ§åˆ¶ä¸Šä¸‹æ–‡ |
| æ ¸å¿ƒæ–¹æ³• | `encode()`ã€`decode()`ã€`encoding_for_model()` |
| æ‡‰ç”¨ | Prompt ç®¡ç†ã€RAGã€API æˆæœ¬é æ¸¬ |

---

Â© 2025 ChatGPT GPT-5

