## CNN 常用元件
- Module: tf.keras.layers | TensorFlow v2.16.1
  - https://www.tensorflow.org/api_docs/python/tf/keras/layers 
- tf.keras.layers.Conv2D
- tf.keras.layers.MaxPool2D
- tf.keras.layers.Dropout

## 檢視CNN 模型
- Module: tf.keras.applications
  - https://www.tensorflow.org/api_docs/python/tf/keras/applications 
- 檢視VGG16模型
```python
from tf.keras.applications import VGG16
model = VGG16()
model.summary()
```
## 簡易資料集
- Kaggle | [MNIST Dataset The MNIST database of handwritten digits (http://yann.lecun.com)](https://www.kaggle.com/datasets/hojjatk/mnist-dataset)
- Kaggle | [Fashion MNIST:An MNIST-like dataset of 70,000 28x28 labeled fashion images](https://www.kaggle.com/datasets/zalando-research/fashionmnist)
## 作業:CNN模型實作
- 請使用keras sequential model 實作lenet-5 資料集用MINST

#### ChatGPT 同學繳交的報告 ==> 理解模型錯誤 ==> AI Hallucination (幻覺)
- Prompt :請使用keras sequential model 實作lenet-5 資料集用MINST
```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical

# 載入 MNIST 資料集
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# 調整資料形狀 (28x28 → 28x28x1)
x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0
x_test  = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0

# One-hot 編碼標籤
y_train = to_categorical(y_train, 10)
y_test  = to_categorical(y_test, 10)

# 建立 LeNet-5 模型
model = Sequential([
    Conv2D(6, kernel_size=(5,5), activation='tanh', input_shape=(28,28,1), padding='same'),
    AveragePooling2D(pool_size=(2,2), strides=2),

    Conv2D(16, kernel_size=(5,5), activation='tanh'),
    AveragePooling2D(pool_size=(2,2), strides=2),

## 這不是LeNet-5 模型 ==> AI Hallucination (幻覺)
    Conv2D(120, kernel_size=(5,5), activation='tanh'),
    Flatten(),
    Dense(84, activation='tanh'),
    Dense(10, activation='softmax')
])

# 編譯模型 ==> 使用compile()
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# 訓練模型  ==> 使用fit()
model.fit(x_train, y_train, batch_size=128, epochs=10, validation_split=0.1)

# 評估模型
test_loss, test_acc = model.evaluate(x_test, y_test)
print("Test accuracy:", test_acc)
```
#### Google Gemini同學繳交的報告
- Prompt 1:請使用keras sequential model 實作lenet-5 資料集用MINST
- Prompt 2:匯出到Google Colab
```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense
from tensorflow.keras.utils import to_categorical
import numpy as np

# 確保 TensorFlow 版本正確
print(f"TensorFlow 版本: {tf.__version__}")

# --- 1. 資料載入與預處理 (Data Loading and Preprocessing) ---

# 載入 MNIST 資料集
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# 1. 重塑 (Reshape) 資料以包含顏色通道 (channel dimension)
# Keras 需要的輸入格式為 (樣本數, 高度, 寬度, 通道數)。灰階圖片通道數為 1。
x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')
x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')

# 2. 數據正規化 (Normalization)
# 將像素值從 0-255 縮放到 0-1
x_train /= 255.0
x_test /= 255.0

# 3. 標籤獨熱編碼 (One-Hot Encoding)
# 將類別標籤 (0-9) 轉換為獨熱向量 (One-Hot Vector)
num_classes = 10
y_train = to_categorical(y_train, num_classes)
y_test = to_categorical(y_test, num_classes)

# 定義模型輸入形狀
input_shape = (28, 28, 1)


# --- 2. 定義 LeNet-5 模型架構 (Define LeNet-5 Architecture) ---

def build_lenet_5(input_shape, num_classes):
    model = Sequential()
    
    # 原始 LeNet-5 使用 tanh 激活函數和 AveragePooling2D
    
    # C1: 卷積層
    model.add(Conv2D(
        filters=6, 
        kernel_size=(5, 5), 
        activation='tanh', 
        input_shape=input_shape, 
        padding='valid' 
    ))
    
    # S2: 平均池化層 (Subsampling Layer)
    model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))
    
    # C3: 卷積層
    model.add(Conv2D(
        filters=16, 
        kernel_size=(5, 5), 
        activation='tanh',
        padding='valid'
    ))
    
    # S4: 平均池化層 (Subsampling Layer)
    model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))
    
    # 展平層 (Flatten) - 轉換為 1D 向量
    model.add(Flatten())
    
    # F5: 全連接層 (Fully Connected Layer)
    model.add(Dense(units=120, activation='tanh'))
    
    # F6: 全連接層
    model.add(Dense(units=84, activation='tanh'))
    
    # 輸出層 (Output Layer) - 使用 softmax 進行分類
    model.add(Dense(units=num_classes, activation='softmax'))
    
    return model

# 建立模型實例
model = build_lenet_5(input_shape, num_classes)

# 打印模型摘要
print("\n--- LeNet-5 模型摘要 ---")
model.summary()

# --- 3. 編譯與訓練模型 (Compile and Train Model) ---

# 模型編譯
model.compile(
    optimizer='adam',                 # 使用 Adam 優化器 (現代常見選擇)
    loss='categorical_crossentropy',  # 適用於多類別分類
    metrics=['accuracy']
)

# 訓練參數
epochs = 10
batch_size = 128

print("\n--- 開始訓練 ---")
history = model.fit(
    x_train, 
    y_train, 
    epochs=epochs, 
    batch_size=batch_size, 
    verbose=1,
    validation_data=(x_test, y_test)
)
print("--- 訓練結束 ---")

# --- 4. 模型評估 (Model Evaluation) ---

print("\n--- 模型最終評估 ---")
score = model.evaluate(x_test, y_test, verbose=0)
print(f'測試集損失 (Test Loss): {score[0]:.4f}')
print(f'測試集準確度 (Test Accuracy): {score[1]:.4f}')
```
