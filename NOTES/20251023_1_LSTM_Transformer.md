## NLP model

## RNN LSTM
- https://colah.github.io/posts/2015-08-Understanding-LSTMs/
- https://distill.pub/2016/augmented-rnns/
- https://en.wikipedia.org/wiki/Long_short-term_memory
- https://www.geeksforgeeks.org/deep-learning/deep-learning-introduction-to-long-short-term-memory/
- https://medium.com/data-science/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21
- https://d2l.ai/chapter_recurrent-modern/lstm.html
- [Understanding LSTM -- a tutorial into Long Short-Term Memory Recurrent Neural Networks](https://arxiv.org/abs/1909.09586)
- MIT 6.S191: Recurrent Neural Networks, Transformers, and Attention
  - https://www.youtube.com/watch?v=GvezxUdLrEk
  - https://introtodeeplearning.com/ 
## Transformer
- 2017 經典論文[[1706.03762] Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- https://jalammar.github.io/illustrated-transformer/
- https://fancyerii.github.io/2019/03/09/transformer-illustrated/#%E6%A6%82%E8%BF%B0
- https://tamoghnasaha-22.medium.com/transformers-illustrated-5c9205a6c70f
- https://zh.wikipedia.org/wiki/Transformer%E6%9E%B6%E6%9E%84
- https://medium.com/data-science/illustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0
- https://medium.com/ching-i/transformer-attention-is-all-you-need-c7967f38af14
