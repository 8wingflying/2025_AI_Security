# Generative AI in Cybersecurity
- (1) Threat Detection and Analysis
- (2) Phishing Detection and Respons
- (3) Incident Response
- (4) Security Automation
- (5) Cyber Forensics
- (6) Chatbots
- (7) Penetration Testing
- (8) Security Protocols Verification
- (9) Security Training and Awareness:
  - LLMs can generate training materials tailored to an organization’s needs.
  - They can also simulate phishing attacks and other security scenarios to train employees to recognize and respond to security threats 


## Review
- Generative AI in Cybersecurity: A Comprehensive Review of LLM Applications and Vulnerabilities
  - https://arxiv.org/abs/2405.12750
- Review of Generative AI Methods in Cybersecurity
  - https://arxiv.org/abs/2403.08701v1

## Project
- PentestGPT(2023.8)
- AutoAttacker(2024.3)
- PTHelper(2024.6)
- BreachSeek(2024.9)
- PentestAgent(2024.11)
- HackSynth(2024.12)
- AutoPentest(2025.5)

## Benchmark
- See https://arxiv.org/pdf/2405.12750
  - TABLE I: Summary of Related Reviews on Large Language Models
  - TABLE II: RNN-based models for Cyber Security
  - TABLE III: Transformer-based models for Cyber Security (Part I).
  - TABLE IV: Transformer-based models for Cyber Security (Part II)
  - Fig. 4: LLM-based Solutions for Cyber Security Use Cases.
  - TABLE V: Comparison of Large Language Models
  - TABLE VIII: Comparison of 19 LLMs Models’ Performance in Hardware Security Knowledge
  - TABLE IX: Comparison of 42 LLMs Models’ Performance in Cyber Security Knowledge
  - TABLE XVII: Comparison of Benchmarks for Evaluating LLMs in Cybersecurity Knowledge
  - TABLE XVIII: Optimization Strategies for Large Language Models in Cybersecurity
- AI-Pentest-Benchmark
  - https://github.com/isamu-isozaki/AI-Pentest-Benchmark 
- Catastrophic Cyber Capabilities Benchmark (3CB)(2024.10)
- CyberSecEval 1 


## Test
- Teams of LLM Agents can Exploit Zero-Day Vulnerabilities
- 
