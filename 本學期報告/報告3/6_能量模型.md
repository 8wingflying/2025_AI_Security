# Energy-Based Models
- https://learning.oreilly.com/library/view/generative-deep-learning/9781098134174/ch07.html#id104

## Model
- Boltzmann machine
  - contrastive divergence
  - Gibbs sampling  [Gibbs Sampling in Python](https://jessicastringham.net/2018/05/09/gibbs-sampling/)
  - Gibbs sampling with long mixing times is still required.
  - 1985 A learning algorithm for boltzmann machines
    - David H. Ackley, Geoffrey E. Hinton, Terrence J. Sejnowski 
- Restricted Boltzmann machine(RBM) 1986

- deep belief networks
  - sampling method for EBMs
  - Gibbs sampling ==> Langevin dynamics ==> score matching  ==> Denoising Diffusion Probabilistic Models


- Yilun Du and Igor Mordatch, “Implicit Generation and Modeling with Energy-Based Models,” March 20, 2019, https://arxiv.org/abs/1903.08689.
- 2 Prajit Ramachandran et al., “Searching for Activation Functions,” October 16, 2017, https://arxiv.org/abs/1710.05941v2.
- 3 Max Welling and Yee Whye Teh, “Bayesian Learning via Stochastic Gradient Langevin Dynamics,” 2011, https://www.stats.ox.ac.uk/~teh/research/compstats/WelTeh2011a.pdf
- 4 Geoffrey E. Hinton, “Training Products of Experts by Minimizing Contrastive Divergence,” 2002, https://www.cs.toronto.edu/~hinton/absps/tr00-004.pdf.
- 5 Oliver Woodford, “Notes on Contrastive Divergence,” 2006, https://www.robots.ox.ac.uk/~ojw/files/NotesOnCD.pdf.
- 6 David H. Ackley et al., “A Learning Algorithm for Boltzmann Machines,” 1985, Cognitive Science 9(1), 147-165.
- 7 Yann Lecun et al., “A Tutorial on Energy-Based Learning,” 2006, https://www.researchgate.net/publication/200744586_A_tutorial_on_energy-based_learning.

## 範例
- [Tutorial 8: Deep Energy-Based Generative Models](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial8/Deep_Energy_Models.html)
- https://deepgenerativemodels.github.io/assets/slides/cs236_lecture11.pdf
